{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Setup: install Qiskit (runs automatically in Colab, no-op in Binder)\n",
    "!pip install -q qiskit qiskit-aer qiskit-ibm-runtime pylatexenc"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Additional dependencies for this notebook\n",
    "!pip install -q imbalanced-learn scikit-learn"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6d1e3ec",
   "metadata": {},
   "source": "# Гібридна квантово-посилена ансамблева класифікація (робочий процес стабільності мережі)\n\n*Оцінка використання: 20 хвилин часу QPU для кожного завдання на процесорі Eagle r3. (ПРИМІТКА: Це лише оцінка. Ваш час виконання може відрізнятися.)*\n## Передумови\nЦей посібник демонструє гібридний квантово-класичний робочий процес, який посилює класичний ансамбль за допомогою кроку квантової оптимізації. Використовуючи \"Singularity Machine Learning – Classification\" від Multiverse Computing (функцію Qiskit), ми навчаємо пул звичайних учнів (наприклад, дерева рішень, k-NN, логістична регресія), а потім вдосконалюємо цей пул за допомогою квантового шару для покращення різноманітності та узагальнення. Мета є практичною: на реальному завданні прогнозування стабільності мережі ми порівнюємо сильну класичну базову лінію з квантово-оптимізованою альтернативою при однакових розділах даних, щоб Ви могли побачити, де квантовий крок допомагає і що він коштує.\n\nЧому це важливо: вибір хорошої підмножини з багатьох слабких учнів є комбінаторною проблемою, яка швидко зростає з розміром ансамблю. Класичні евристики, такі як бустинг, беггінг та стекінг, добре працюють у помірних масштабах, але можуть мати труднощі з ефективним дослідженням великих, надлишкових бібліотек моделей. Функція інтегрує квантові алгоритми - зокрема QAOA (і додатково VQE в інших конфігураціях) - для більш ефективного пошуку в цьому просторі після того, як класичні учні навчені, збільшуючи шанс знайти компактну, різноманітну підмножину, яка краще узагальнює.\n\nВажливо, що масштаб даних не обмежений кубітами. Важка робота з даними — попередня обробка, навчання пулу учнів та оцінювання — залишається класичною і може обробляти мільйони прикладів. Кубіти визначають лише розмір ансамблю, який використовується на етапі квантового вибору. Це розділення є тим, що робить підхід життєздатним на сучасному обладнанні: Ви зберігаєте знайомі робочі процеси scikit-learn для даних та навчання моделей, викликаючи квантовий крок через чистий інтерфейс дій у Qiskit Functions.\n\nНа практиці, хоча різні типи учнів можуть бути надані ансамблю (наприклад, дерева рішень, логістична регресія або k-NN), дерева рішень, як правило, працюють найкраще. Оптимізатор послідовно віддає перевагу сильнішим членам ансамблю — коли надаються гетерогенні учні, слабші моделі, такі як лінійні регресори, зазвичай видаляються на користь більш виразних моделей, таких як дерева рішень.\n\nЩо Ви будете робити тут: підготувати та збалансувати набір даних стабільності мережі; встановити класичну базову лінію AdaBoost; запустити кілька квантових конфігурацій, які змінюють ширину ансамблю та регуляризацію; виконати на симуляторах IBM&reg; або QPU через Qiskit Serverless; та порівняти точність, прецизійність, повноту та F1 у всіх запусках. По дорозі Ви будете використовувати шаблон дій функції (`create`, `fit`, `predict`, `fit_predict`, `create_fit_predict`) та ключові елементи управління:\n- Типи регуляризації: `onsite` (λ) для прямої розрідженості та `alpha` для компромісу на основі співвідношення між термінами взаємодії та onsite\n- Авто-регуляризація: встановіть `regularization=\"auto\"` з цільовим коефіцієнтом вибору для автоматичної адаптації розрідженості\n- Опції оптимізатора: симулятор проти QPU, повторення, класичний оптимізатор та його опції, глибина транспіляції та налаштування семплера/оцінювача виконання\n\nБенчмарки в документації показують, що точність покращується зі збільшенням кількості учнів (кубітів) на складних проблемах, причому квантовий класифікатор відповідає або перевищує порівнянний класичний ансамбль. У цьому посібнику Ви відтворите робочий процес від початку до кінця та дослідите, коли збільшення ширини ансамблю або перемикання на адаптивну регуляризацію дає кращий F1 при розумному використанні ресурсів. Результатом є обґрунтований погляд на те, як крок квантової оптимізації може доповнити, а не замінити, класичне ансамблеве навчання в реальних застосуваннях.\n## Вимоги\nПеред початком цього посібника переконайтеся, що у Вашому середовищі Python встановлені наступні пакети:\n\n- `qiskit[visualization]~=2.1.0`\n- `qiskit-serverless~=0.24.0`\n- `qiskit-ibm-runtime v0.40.1`\n- `qiskit-ibm-catalog~=0.8.0`\n- `scikit-learn==1.5.2`\n- `pandas>=2.0.0,<3.0.0`\n- `imbalanced-learn~=0.12.3`\n## Налаштування\nУ цьому розділі ми ініціалізуємо клієнт Qiskit Serverless та завантажуємо функцію Singularity Machine Learning – Classification, надану Multiverse Computing.\nЗа допомогою Qiskit Serverless Ви можете виконувати гібридні квантово-класичні робочі процеси на керованій хмарній інфраструктурі IBM, не турбуючись про управління ресурсами.\nВам знадобиться ключ API IBM Quantum Platform та ім'я ресурсу хмари (CRN) для автентифікації та доступу до Qiskit Functions.\n### Завантаження набору даних\nЩоб виконати цей посібник, ми використовуємо попередньо оброблений **набір даних класифікації стабільності мережі**, що містить позначені показання датчиків енергосистеми.\nНаступна комірка автоматично створює необхідну структуру папок та завантажує як навчальні, так і тестові файли безпосередньо у Ваше середовище за допомогою `wget`.\nЯкщо у Вас вже є ці файли локально, цей крок безпечно перезапише їх, щоб забезпечити узгодженість версій."
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "a6f69b77",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "8bf80006",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "55b94021",
   "metadata": {},
   "source": ""
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "7db2e559",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "markdown",
   "id": "d4fe7ee1-21ce-445c-b151-598cd4cf9227",
   "metadata": {},
   "source": ""
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "7a32efb3-a425-4c02-804b-65029ecffb6f",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "data_tutorial/grid_ 100%[===================>] 612.94K  --.-KB/s    in 0.01s   \n",
      "data_tutorial/grid_ 100%[===================>] 108.19K  --.-KB/s    in 0.006s  \n",
      "Dataset files downloaded:\n",
      "-rw-r--r-- 1 coder coder 109K Nov  8 18:50 data_tutorial/grid_stability/test.csv\n",
      "-rw-r--r-- 1 coder coder 613K Nov  8 18:50 data_tutorial/grid_stability/train.csv\n"
     ]
    }
   ],
   "source": [
    "## Download dataset for Grid Stability Classification\n",
    "\n",
    "# Create data directory if it doesn't exist\n",
    "!mkdir -p data_tutorial/grid_stability\n",
    "\n",
    "# Download the training and test sets from the official Qiskit documentation repo\n",
    "!wget -q --show-progress -O data_tutorial/grid_stability/train.csv \\\n",
    "  https://raw.githubusercontent.com/Qiskit/documentation/main/datasets/tutorials/grid_stability/train.csv\n",
    "\n",
    "!wget -q --show-progress -O data_tutorial/grid_stability/test.csv \\\n",
    "  https://raw.githubusercontent.com/Qiskit/documentation/main/datasets/tutorials/grid_stability/test.csv\n",
    "\n",
    "# Check the files have been downloaded\n",
    "!echo \"Dataset files downloaded:\"\n",
    "!ls -lh data_tutorial/grid_stability/*.csv"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "bb9aa84f-ab37-412c-b056-7043b73380fa",
   "metadata": {},
   "source": [
    "### Import required packages\n",
    "\n",
    "In this section, we import all Python packages and Qiskit modules used throughout the tutorial.\n",
    "These include core scientific libraries for data handling and model evaluation - such as `NumPy`, `pandas`, and `scikit-learn` - along with visualization tools and Qiskit components for running the quantum-enhanced model.\n",
    "We also import the `QiskitRuntimeService` and `QiskitFunctionsCatalog` to connect with IBM Quantum&reg; services and access the Singularity Machine Learning function."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "f8c654f5-8355-4f67-b79d-c2b1c29ccc62",
   "metadata": {},
   "outputs": [],
   "source": [
    "from typing import Tuple\n",
    "import warnings\n",
    "\n",
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from imblearn.over_sampling import RandomOverSampler\n",
    "from qiskit_ibm_catalog import QiskitFunctionsCatalog\n",
    "from qiskit_ibm_runtime import QiskitRuntimeService\n",
    "from sklearn.ensemble import AdaBoostClassifier\n",
    "from sklearn.metrics import (\n",
    "    accuracy_score,\n",
    "    f1_score,\n",
    "    precision_score,\n",
    "    recall_score,\n",
    ")\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "warnings.filterwarnings(\"ignore\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3b389b34-02e8-4a63-ae24-0bf348647b48",
   "metadata": {},
   "source": "### Імпорт необхідних пакетів\nУ цьому розділі ми імпортуємо всі пакети Python та модулі Qiskit, які використовуються в посібнику.\nВони включають основні наукові бібліотеки для обробки даних та оцінювання моделей - такі як `NumPy`, `pandas` та `scikit-learn` - разом з інструментами візуалізації та компонентами Qiskit для запуску квантово-посиленої моделі.\nМи також імпортуємо `QiskitRuntimeService` та `QiskitFunctionsCatalog` для підключення до сервісів IBM Quantum&reg; та доступу до функції Singularity Machine Learning."
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "a68bf7df-914c-4b2a-827f-657578503750",
   "metadata": {},
   "outputs": [],
   "source": [
    "IBM_TOKEN = \"\"\n",
    "IBM_INSTANCE_TEST = \"\"\n",
    "IBM_INSTANCE_QUANTUM = \"\"\n",
    "FUNCTION_NAME = \"multiverse/singularity\"\n",
    "RANDOM_STATE: int = 123\n",
    "TRAIN_PATH = \"data_tutorial/grid_stability/train.csv\"\n",
    "TEST_PATH = \"data_tutorial/grid_stability/test.csv\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4709dc1c-b380-49f1-95c7-89197aa5e147",
   "metadata": {},
   "source": "### Встановлення постійних змінних"
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "bc380c46",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Successfully connected to IBM Qiskit Serverless and loaded the Singularity function.\n",
      "Catalog: <QiskitFunctionsCatalog>\n",
      "Singularity function: QiskitFunction(multiverse/singularity)\n"
     ]
    }
   ],
   "source": [
    "service = QiskitRuntimeService(\n",
    "    token=IBM_TOKEN,\n",
    "    channel=\"ibm_quantum_platform\",\n",
    "    instance=IBM_INSTANCE_QUANTUM,\n",
    ")\n",
    "\n",
    "backend = service.least_busy()\n",
    "catalog = QiskitFunctionsCatalog(\n",
    "    token=IBM_TOKEN,\n",
    "    instance=IBM_INSTANCE_TEST,\n",
    "    channel=\"ibm_quantum_platform\",\n",
    ")\n",
    "singularity = catalog.load(FUNCTION_NAME)\n",
    "print(\n",
    "    \"Successfully connected to IBM Qiskit Serverless and loaded the Singularity function.\"\n",
    ")\n",
    "print(\"Catalog:\", catalog)\n",
    "print(\"Singularity function:\", singularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "47d6a559-118a-4aa9-874d-9c009b5da60c",
   "metadata": {},
   "source": "### Підключення до IBM Quantum та завантаження функції Singularity\nДалі ми автентифікуємося в сервісах IBM Quantum та завантажуємо функцію Singularity Machine Learning – Classification з каталогу Qiskit Functions Catalog.\n`QiskitRuntimeService` встановлює безпечне з'єднання з IBM Quantum Platform, використовуючи Ваш токен API та CRN екземпляра, дозволяючи доступ до квантових бекендів.\nПотім використовується `QiskitFunctionsCatalog` для отримання функції Singularity за назвою (`\"multiverse/singularity\"`), що дозволяє нам викликати її пізніше для гібридних квантово-класичних обчислень.\nЯкщо налаштування успішне, Ви побачите підтверджувальне повідомлення, що вказує, що функція завантажена правильно."
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "46bc841e-7365-4508-b6bf-ae57db6050e1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_data(data_path: str) -> Tuple[np.ndarray, np.ndarray]:\n",
    "    \"\"\"Load data from the given path to X and y arrays.\"\"\"\n",
    "    df: pd.DataFrame = pd.read_csv(data_path)\n",
    "    return df.iloc[:, :-1].values, df.iloc[:, -1].values\n",
    "\n",
    "\n",
    "def evaluate_predictions(predictions, y_true):\n",
    "    \"\"\"Compute and print accuracy, precision, recall, and F1 score.\"\"\"\n",
    "    accuracy = accuracy_score(y_true, predictions)\n",
    "    precision = precision_score(y_true, predictions)\n",
    "    recall = recall_score(y_true, predictions)\n",
    "    f1 = f1_score(y_true, predictions)\n",
    "    print(\"Accuracy:\", accuracy)\n",
    "    print(\"Precision:\", precision)\n",
    "    print(\"Recall:\", recall)\n",
    "    print(\"F1:\", f1)\n",
    "    return accuracy, precision, recall, f1"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "988ee237",
   "metadata": {},
   "source": [
    "## Step 1: Map classical inputs to a quantum problem\n",
    "\n",
    "We begin by preparing the dataset for hybrid quantum–classical experimentation. The goal of this step is to convert the raw grid-stability data into balanced training, validation, and test splits that can be used consistently by both classical and quantum workflows. Maintaining identical splits ensures that later performance comparisons are fair and reproducible."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1c084cde-a5cf-4661-a00c-aa243c8b0e44",
   "metadata": {},
   "source": [
    "### Data loading and preprocessing\n",
    "\n",
    "We first load the training and test CSV files, create a validation split, and balance the dataset using random over-sampling. Balancing prevents bias toward the majority class and provides a more stable learning signal for both classical and quantum ensemble models."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "0db0e914-a8f2-4a04-bec7-c15bac8104b4",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Shapes:\n",
      "  X_train_bal: (5104, 12)\n",
      "  y_train_bal: (5104,)\n",
      "  X_val: (850, 12)\n",
      "  y_val: (850,)\n",
      "  X_test: (750, 12)\n",
      "  y_test: (750,)\n"
     ]
    }
   ],
   "source": [
    "# Load and upload the data\n",
    "X_train, y_train = load_data(TRAIN_PATH)\n",
    "X_test, y_test = load_data(TEST_PATH)\n",
    "X_train, X_val, y_train, y_val = train_test_split(\n",
    "    X_train, y_train, test_size=0.2, random_state=RANDOM_STATE\n",
    ")\n",
    "\n",
    "# Balance the dataset through over-sampling of the positive class\n",
    "ros = RandomOverSampler(random_state=RANDOM_STATE)\n",
    "X_train_bal, y_train_bal = ros.fit_resample(X_train, y_train)\n",
    "\n",
    "print(\"Shapes:\")\n",
    "print(\"  X_train_bal:\", X_train_bal.shape)\n",
    "print(\"  y_train_bal:\", y_train_bal.shape)\n",
    "print(\"  X_val:\", X_val.shape)\n",
    "print(\"  y_val:\", y_val.shape)\n",
    "print(\"  X_test:\", X_test.shape)\n",
    "print(\"  y_test:\", y_test.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b8c214fd-09a8-4fa5-ab83-b0c71ad615d4",
   "metadata": {},
   "source": "### Визначення допоміжних функцій\nПеред запуском основних експериментів ми визначаємо кілька невеликих допоміжних функцій, які спрощують завантаження даних та оцінювання моделей.\n- `load_data()` зчитує вхідні CSV файли в масиви NumPy, розділяючи ознаки та мітки для сумісності з `scikit-learn` та квантовими робочими процесами.\n- `evaluate_predictions()` обчислює ключові метрики продуктивності - точність, прецизійність, повноту та F1-оцінку - і додатково повідомляє час виконання, якщо надається інформація про хронометраж.\n\nЦі допоміжні функції спрощують повторювані операції пізніше в ноутбуці та забезпечують послідовне звітування метрик як для класичних, так і для квантових класифікаторів."
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "38ecd608-35b4-4e58-8a16-85ef98bf024a",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Classical AdaBoost baseline:\n",
      "Accuracy: 0.7893333333333333\n",
      "Precision: 1.0\n",
      "Recall: 0.7893333333333333\n",
      "F1: 0.8822652757078987\n"
     ]
    }
   ],
   "source": [
    "# ----- Classical baseline: AdaBoost -----\n",
    "baseline = AdaBoostClassifier(n_estimators=60, random_state=RANDOM_STATE)\n",
    "baseline.fit(X_train_bal, y_train_bal)\n",
    "baseline_pred = baseline.predict(X_test)\n",
    "print(\"Classical AdaBoost baseline:\")\n",
    "_ = evaluate_predictions(baseline_pred, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ac6f36e3",
   "metadata": {},
   "source": "## Крок 1: Відображення класичних вхідних даних на квантову проблему\nМи починаємо з підготовки набору даних для гібридного квантово-класичного експериментування. Метою цього кроку є перетворення необроблених даних стабільності мережі в збалансовані навчальні, валідаційні та тестові розділи, які можуть послідовно використовуватися як класичними, так і квантовими робочими процесами. Підтримка ідентичних розділів забезпечує справедливе та відтворюване порівняння продуктивності пізніше.\n### Завантаження та попередня обробка даних\nСпочатку ми завантажуємо навчальні та тестові CSV файли, створюємо валідаційний розділ та балансуємо набір даних за допомогою випадкової надвибірки. Балансування запобігає зміщенню до класу більшості та забезпечує більш стабільний навчальний сигнал як для класичних, так і для квантових ансамблевих моделей."
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "18c0d3f9-691b-449d-83ca-e6bfce2d6b99",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Configured hardware optimization profile:\n",
      "  simulator: False\n",
      "  num_solutions: 100000\n",
      "  reps: 3\n",
      "  optimization_level: 3\n",
      "  num_transpiler_runs: 30\n",
      "  classical_optimizer: COBYLA\n",
      "  classical_optimizer_options: {'maxiter': 60}\n",
      "  estimator_options: None\n",
      "  sampler_options: None\n"
     ]
    }
   ],
   "source": [
    "# QAOA / runtime configuration for best results on hardware\n",
    "optimizer_options = {\n",
    "    \"simulator\": False,  # set True to test locally without QPU\n",
    "    \"num_solutions\": 100_000,  # broaden search over candidate ensembles\n",
    "    \"reps\": 3,  # QAOA depth (circuit layers)\n",
    "    \"optimization_level\": 3,  # transpilation effort\n",
    "    \"num_transpiler_runs\": 30,  # explore multiple layouts\n",
    "    \"classical_optimizer\": \"COBYLA\",  # robust default for this landscape\n",
    "    \"classical_optimizer_options\": {\n",
    "        \"maxiter\": 60  # practical convergence budget\n",
    "    },\n",
    "    # You can pass backend-specific options; leaving None uses least-busy routing\n",
    "    \"estimator_options\": None,\n",
    "    \"sampler_options\": None,\n",
    "}\n",
    "\n",
    "print(\"Configured hardware optimization profile:\")\n",
    "for key, value in optimizer_options.items():\n",
    "    print(f\"  {key}: {value}\")"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "b4d480b3",
   "metadata": {},
   "source": [
    "## Step 3: Execute using Qiskit primitives\n",
    "\n",
    "We now execute the full workflow using the Singularity function’s `create_fit_predict` action to train, optimize, and evaluate the `QuantumEnhancedEnsembleClassifier` end-to-end on IBM infrastructure. The function builds the ensemble, applies quantum optimization through Qiskit primitives, and returns both predictions and job metadata (including runtime and resource usage). The classical data split from Step 1 is reused for reproducibility, with validation data passed through `fit_params` so the optimization can tune hyperparameters internally while keeping the held-out test set untouched.\n",
    "\n",
    "In this step, we explore several configurations of the quantum ensemble to understand how key parameters - specifically `num_learners` and `regularization` - affect both result quality and QPU usage.\n",
    "- `num_learners` determines the ensemble width (and implicitly, the number of qubits), influencing the model’s capacity and computational cost.\n",
    "- `regularization` controls sparsity and overfitting, shaping how many learners remain active after optimization.\n",
    "\n",
    "By varying these parameters, we can see how ensemble width and regularization interact: increasing width typically improves F1 but costs more QPU time, while stronger or adaptive regularization can improve generalization at roughly the same hardware footprint. The next subsections walk through three representative configurations to illustrate these effects."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8da41d4d-f06d-4b67-a8ee-b07fc0289558",
   "metadata": {},
   "source": [
    "### Baseline\n",
    "\n",
    "This configuration uses `num_learners = 10` and `regularization = 7`.\n",
    "\n",
    "- `num_learners` controls the ensemble width — effectively the number of weak learners combined and, on quantum hardware, the **number of qubits required**. A larger value expands the combinatorial search space and can improve accuracy and recall, but also increases circuit width, compilation time, and overall QPU usage.\n",
    "- `regularization` sets the penalty strength for including additional learners. With the default \"onsite\" regularization, higher values enforce stronger sparsity (fewer learners kept), while lower values allow more complex ensembles.\n",
    "\n",
    "This setup provides a low-cost baseline, showing how a small ensemble behaves before scaling width or tuning sparsity."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "e702c986-fd7f-4ea1-a93c-8cd5ef0c4a0b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem scale and regularization\n",
    "NUM_LEARNERS = 10\n",
    "REGULARIZATION = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "06c261c1-a3c1-42c9-a522-63f3fc01a970",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Submitting quantum-enhanced ensemble job --\n",
      "Action status: ok\n",
      "Action message: Classifier created, fitted, and predicted.\n",
      "Metadata: {'resource_usage': {'RUNNING: MAPPING': {'CPU_TIME': 267.05158376693726}, 'RUNNING: WAITING_QPU': {'CPU_TIME': 3336.8785166740417}, 'RUNNING: POST_PROCESSING': {'CPU_TIME': 152.4274561405182}, 'RUNNING: EXECUTING_QPU': {'QPU_TIME': 1550.1889700889587}}}\n",
      "Accuracy: 0.868\n",
      "Precision: 1.0\n",
      "Recall: 0.868\n",
      "F1: 0.9293361884368309\n"
     ]
    }
   ],
   "source": [
    "# ----- Quantum-enhanced ensemble on IBM hardware -----\n",
    "print(\"\\n-- Submitting quantum-enhanced ensemble job --\")\n",
    "job_1 = singularity.run(\n",
    "    action=\"create_fit_predict\",\n",
    "    name=\"grid_stability_qeec\",\n",
    "    quantum_classifier=\"QuantumEnhancedEnsembleClassifier\",\n",
    "    num_learners=NUM_LEARNERS,\n",
    "    regularization=REGULARIZATION,\n",
    "    optimizer_options=optimizer_options,  # from Step 2\n",
    "    backend_name=backend,  # least-busy compatible backend\n",
    "    instance=IBM_INSTANCE_QUANTUM,\n",
    "    random_state=RANDOM_STATE,\n",
    "    X_train=X_train_bal,\n",
    "    y_train=y_train_bal,\n",
    "    X_test=X_test,\n",
    "    fit_params={\"validation_data\": (X_val, y_val)},\n",
    "    options={\"save\": False},\n",
    ")\n",
    "result_1 = job_1.result()\n",
    "print(\"Action status:\", result_1.get(\"status\"))\n",
    "print(\"Action message:\", result_1.get(\"message\"))\n",
    "print(\"Metadata:\", result_1.get(\"metadata\"))\n",
    "qeec_pred_job_1 = np.array(result_1[\"data\"][\"predictions\"])\n",
    "_ = evaluate_predictions(qeec_pred_job_1, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "1bf0a3ae-b5b8-43d7-b72d-5a9cf6c61060",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantum job status: DONE\n"
     ]
    }
   ],
   "source": [
    "status_1 = job_1.status()\n",
    "print(\"\\nQuantum job status:\", status_1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ae62b414-db77-45aa-bf2c-a8537fd7eba0",
   "metadata": {},
   "source": "## Крок 2: Оптимізація проблеми для виконання на квантовому обладнанні\nЗавдання вибору ансамблю формулюється як проблема комбінаторної оптимізації, де кожен слабкий учень є бінарною змінною рішення, а цільова функція балансує точність з розрідженістю через член регуляризації. `QuantumEnhancedEnsembleClassifier` вирішує це за допомогою QAOA на обладнанні IBM, все ще дозволяючи дослідження на основі симулятора. `optimizer_options` контролюють гібридний цикл: `simulator=False` направляє схеми до вибраного QPU, `num_solutions` збільшує широту пошуку, а `classical_optimizer_options` (для внутрішнього класичного оптимізатора) керують збіжністю; значення близько 60 ітерацій є хорошим балансом для якості та часу виконання. Опції виконання - такі як помірна глибина схеми (`reps`) та стандартне зусилля транспіляції - допомагають забезпечити надійну продуктивність на різних пристроях. Конфігурація нижче є профілем \"найкращих результатів\", який ми будемо використовувати для запусків на обладнанні; Ви також можете створити суто симульований варіант, перемкнувши `simulator=True`, щоб виконати пробний запуск робочого процесу без витрати часу QPU."
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "e5fe64b0-2713-4b65-b768-10fa5d8dbf79",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem scale and regularization\n",
    "NUM_LEARNERS = 30\n",
    "REGULARIZATION = 7"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "18a22fed-41c2-4407-88d4-02fbd32f3320",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Submitting quantum-enhanced ensemble job --\n",
      "Action status: ok\n",
      "Action message: Classifier created, fitted, and predicted.\n",
      "QPU Time: {'resource_usage': {'RUNNING: MAPPING': {'CPU_TIME': 680.2116754055023}, 'RUNNING: WAITING_QPU': {'CPU_TIME': 80.80395102500916}, 'RUNNING: POST_PROCESSING': {'CPU_TIME': 154.4466371536255}, 'RUNNING: EXECUTING_QPU': {'QPU_TIME': 1095.822762966156}}}\n",
      "Accuracy: 0.8946666666666667\n",
      "Precision: 1.0\n",
      "Recall: 0.8946666666666667\n",
      "F1: 0.944405348346235\n"
     ]
    }
   ],
   "source": [
    "# ----- Quantum-enhanced ensemble on IBM hardware -----\n",
    "print(\"\\n-- Submitting quantum-enhanced ensemble job --\")\n",
    "job_2 = singularity.run(\n",
    "    action=\"create_fit_predict\",\n",
    "    name=\"grid_stability_qeec\",\n",
    "    quantum_classifier=\"QuantumEnhancedEnsembleClassifier\",\n",
    "    num_learners=NUM_LEARNERS,\n",
    "    regularization=REGULARIZATION,\n",
    "    optimizer_options=optimizer_options,  # from Step 2\n",
    "    backend_name=backend,  # least-busy compatible backend\n",
    "    instance=IBM_INSTANCE_QUANTUM,\n",
    "    random_state=RANDOM_STATE,\n",
    "    X_train=X_train_bal,\n",
    "    y_train=y_train_bal,\n",
    "    X_test=X_test,\n",
    "    fit_params={\"validation_data\": (X_val, y_val)},\n",
    "    options={\"save\": False},\n",
    ")\n",
    "result_2 = job_2.result()\n",
    "print(\"Action status:\", result_2.get(\"status\"))\n",
    "print(\"Action message:\", result_2.get(\"message\"))\n",
    "print(\"QPU Time:\", result_2.get(\"metadata\"))\n",
    "qeec_pred_job_2 = np.array(result_2[\"data\"][\"predictions\"])\n",
    "_ = evaluate_predictions(qeec_pred_job_2, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "edd22b98-7ae6-4444-8fe5-7279e9233c57",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantum job status: DONE\n"
     ]
    }
   ],
   "source": [
    "status_2 = job_2.status()\n",
    "print(\"\\nQuantum job status:\", status_2)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5e94784a-3599-4911-ade9-4792b50c31bb",
   "metadata": {},
   "source": [
    "### Regularization\n",
    "\n",
    "In this configuration, we increase to `num_learners = 60` and introduce adaptive regularization to manage sparsity more intuitively.\n",
    "\n",
    "- With `regularization = \"auto\"`, the optimizer automatically finds a suitable regularization strength that selects approximately `regularization_ratio * num_learners` weak learners for the final ensemble, rather than fixing the penalty manually. This provides a more convenient interface for managing the balance between sparsity and ensemble size.\n",
    "- `regularization_type = \"alpha\"` defines how the penalty is applied. Unlike `onsite`, which is unbounded `[0, ∞]`, `alpha` is bounded between `[0, 1]`, making it easier to tune and interpret. The parameter controls the trade-off between individual and pairwise penalties, offering a smoother configuration range.\n",
    "- `regularization_desired_ratio ≈ 0.82` specifies the target proportion of learners to keep active after regularization — here, around 82% of learners are retained, trimming the weakest 18% automatically.\n",
    "\n",
    "While adaptive regularization simplifies configuration and helps maintain a balanced ensemble, it does not necessarily guarantee better or more stable performance. The actual quality depends on selecting an appropriate regularization parameter, and fine-tuning it through cross-validation can be computationally expensive. The main advantage lies in improved usability and interpretability rather than direct accuracy gains."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "209eb51a-e44b-4f94-8975-269ec7e3d1ca",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Problem scale and regularization\n",
    "NUM_LEARNERS = 60\n",
    "REGULARIZATION = \"auto\"\n",
    "REGULARIZATION_TYPE = \"alpha\"\n",
    "REGULARIZATION_RATIO = 0.82"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "eb2aa9db-4427-48de-aae0-c5c1da1cb998",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "-- Submitting quantum-enhanced ensemble job --\n",
      "Action status: ok\n",
      "Action message: Classifier created, fitted, and predicted.\n",
      "Metadata: {'resource_usage': {'RUNNING: MAPPING': {'CPU_TIME': 1387.7451872825623}, 'RUNNING: WAITING_QPU': {'CPU_TIME': 95.41597843170166}, 'RUNNING: POST_PROCESSING': {'CPU_TIME': 171.78878355026245}, 'RUNNING: EXECUTING_QPU': {'QPU_TIME': 1146.5584812164307}}}\n",
      "Accuracy: 0.908\n",
      "Precision: 1.0\n",
      "Recall: 0.908\n",
      "F1: 0.9517819706498952\n"
     ]
    }
   ],
   "source": [
    "# ----- Quantum-enhanced ensemble on IBM hardware -----\n",
    "print(\"\\n-- Submitting quantum-enhanced ensemble job --\")\n",
    "job_3 = singularity.run(\n",
    "    action=\"create_fit_predict\",\n",
    "    name=\"grid_stability_qeec\",\n",
    "    quantum_classifier=\"QuantumEnhancedEnsembleClassifier\",\n",
    "    num_learners=NUM_LEARNERS,\n",
    "    regularization=REGULARIZATION,\n",
    "    regularization_type=REGULARIZATION_TYPE,\n",
    "    regularization_desired_ratio=REGULARIZATION_RATIO,\n",
    "    optimizer_options=optimizer_options,  # from Step 2\n",
    "    backend_name=backend,  # least-busy compatible backend\n",
    "    instance=IBM_INSTANCE_QUANTUM,\n",
    "    random_state=RANDOM_STATE,\n",
    "    X_train=X_train_bal,\n",
    "    y_train=y_train_bal,\n",
    "    X_test=X_test,\n",
    "    fit_params={\"validation_data\": (X_val, y_val)},\n",
    "    options={\"save\": False},\n",
    ")\n",
    "result_3 = job_3.result()\n",
    "print(\"Action status:\", result_3.get(\"status\"))\n",
    "print(\"Action message:\", result_3.get(\"message\"))\n",
    "print(\"Metadata:\", result_3.get(\"metadata\"))\n",
    "qeec_pred_job_3 = np.array(result_3[\"data\"][\"predictions\"])\n",
    "_ = evaluate_predictions(qeec_pred_job_3, y_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "299b36cb-0ed8-4af3-b431-a87daec04c93",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Quantum job status: DONE\n"
     ]
    }
   ],
   "source": [
    "status_3 = job_3.status()\n",
    "print(\"\\nQuantum job status:\", status_3)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50b94af2",
   "metadata": {},
   "source": [
    "## Step 4: Post-process and return result in desired classical format\n",
    "\n",
    "We now post-process outputs from both the classical and quantum runs, converting them into a consistent format for downstream evaluation. This step compares predictive quality using standard metrics - accuracy, precision, recall, and F1 - and analyzes how ensemble width (`num_learners`) and sparsity control (`regularization`) influence both performance and computational behavior.\n",
    "\n",
    "The classical AdaBoost baseline provides a compact and stable reference for small-scale learning. It performs well with limited ensembles and negligible compute overhead, reflecting the strength of traditional boosting when the hypothesis space is still tractable. The quantum configurations (`qeec_pred_job_1`, `qeec_pred_job_2`, and `qeec_pred_job_3`) extend this baseline by embedding the ensemble-selection process within a variational quantum optimization loop. This allows the system to explore exponentially large subsets of learners simultaneously in superposition, addressing the combinatorial nature of ensemble selection more efficiently as scale increases.\n",
    "\n",
    "Results show that increasing `num_learners` from 10 to 30 improves recall and F1, confirming that a wider ensemble captures richer interactions among weak learners. The gain is sublinear on current hardware - each additional learner yields smaller accuracy increments - but the underlying scaling behavior remains favorable because the quantum optimizer can search broader configuration spaces without the exponential blow-up typical of classical subset selection. Regularization introduces additional nuance: a fixed λ=7 enforces consistent sparsity and stabilizes convergence, whereas adaptive α-regularization automatically tunes sparsity based on correlations between learners. This dynamic pruning often achieves slightly higher F1 for the same qubit width, balancing model complexity and generalization.\n",
    "\n",
    "When compared directly with the AdaBoost baseline, the smallest quantum configuration (L=10) reproduces similar accuracy, validating the hybrid pipeline’s correctness. At larger widths, quantum variants - especially with auto-regularization - begin to surpass the classical baseline modestly, showing improved recall and F1 without linear growth in computational cost. These improvements do not indicate immediate \"quantum advantage\" but rather **scaling efficiency**: the quantum optimizer maintains tractable performance as the ensemble expands, where a classical approach would face exponential growth in subset-selection complexity.\n",
    "\n",
    "In practice:\n",
    "- Use the **classical baseline** for quick validation and benchmarking on small datasets.\n",
    "- Apply **quantum ensembles** when model width or feature complexity grows—QAOA-based search scales more gracefully in those regimes.\n",
    "- Employ **adaptive α-regularization** to maintain sparsity and generalization without increasing circuit width.\n",
    "- Monitor QPU time and depth to balance quality gains against near-term hardware constraints.\n",
    "\n",
    "Together, these experiments show that quantum-optimized ensembles complement classical methods: they reproduce baseline accuracy at small scales while offering a path to efficient scaling on larger, combinatorial learning problems. As hardware improves, these scaling advantages are expected to compound, extending the feasible size and depth of ensemble-based models beyond what is classically practical."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1cf1d610-f2e2-482c-af05-a882bb380528",
   "metadata": {},
   "source": [
    "### Evaluate metrics for each configuration\n",
    "\n",
    "We now evaluate all configurations - the classical AdaBoost baseline and the three quantum ensembles - using the `evaluate_predictions` helper to compute accuracy, precision, recall, and F1 on the same test set. This comparison clarifies how quantum optimization scales relative to the classical approach: at small widths, both perform similarly; as ensembles grow, the quantum method can explore larger hypothesis spaces more efficiently. The resulting table captures these trends in a consistent, quantitative form."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ee8cc821-8311-4c84-8f94-ffb2ec3facc3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.7893333333333333\n",
      "Precision: 1.0\n",
      "Recall: 0.7893333333333333\n",
      "F1: 0.8822652757078987\n",
      "Accuracy: 0.868\n",
      "Precision: 1.0\n",
      "Recall: 0.868\n",
      "F1: 0.9293361884368309\n",
      "Accuracy: 0.8946666666666667\n",
      "Precision: 1.0\n",
      "Recall: 0.8946666666666667\n",
      "F1: 0.944405348346235\n",
      "Accuracy: 0.908\n",
      "Precision: 1.0\n",
      "Recall: 0.908\n",
      "F1: 0.9517819706498952\n"
     ]
    },
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Config</th>\n",
       "      <th>Accuracy</th>\n",
       "      <th>Precision</th>\n",
       "      <th>Recall</th>\n",
       "      <th>F1</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>AdaBoost (Classical)</td>\n",
       "      <td>0.789333</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.789333</td>\n",
       "      <td>0.882265</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>QEEC L=10, reg=7</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.868000</td>\n",
       "      <td>0.929336</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>QEEC L=30, reg=7</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.894667</td>\n",
       "      <td>0.944405</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>QEEC L=60, reg=auto (α=0.82)</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>1.0</td>\n",
       "      <td>0.908000</td>\n",
       "      <td>0.951782</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                         Config  Accuracy  Precision    Recall        F1\n",
       "0          AdaBoost (Classical)  0.789333        1.0  0.789333  0.882265\n",
       "1              QEEC L=10, reg=7  0.868000        1.0  0.868000  0.929336\n",
       "2              QEEC L=30, reg=7  0.894667        1.0  0.894667  0.944405\n",
       "3  QEEC L=60, reg=auto (α=0.82)  0.908000        1.0  0.908000  0.951782"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "results = []\n",
    "\n",
    "# Classical baseline\n",
    "acc_b, prec_b, rec_b, f1_b = evaluate_predictions(baseline_pred, y_test)\n",
    "results.append(\n",
    "    {\n",
    "        \"Config\": \"AdaBoost (Classical)\",\n",
    "        \"Accuracy\": acc_b,\n",
    "        \"Precision\": prec_b,\n",
    "        \"Recall\": rec_b,\n",
    "        \"F1\": f1_b,\n",
    "    }\n",
    ")\n",
    "\n",
    "# Quantum runs\n",
    "for label, preds in [\n",
    "    (\"QEEC L=10, reg=7\", qeec_pred_job_1),\n",
    "    (\"QEEC L=30, reg=7\", qeec_pred_job_2),\n",
    "    (f\"QEEC L=60, reg=auto (α={REGULARIZATION_RATIO})\", qeec_pred_job_3),\n",
    "]:\n",
    "    acc, prec, rec, f1 = evaluate_predictions(preds, y_test)\n",
    "    results.append(\n",
    "        {\n",
    "            \"Config\": label,\n",
    "            \"Accuracy\": acc,\n",
    "            \"Precision\": prec,\n",
    "            \"Recall\": rec,\n",
    "            \"F1\": f1,\n",
    "        }\n",
    "    )\n",
    "\n",
    "\n",
    "df_results = pd.DataFrame(results)\n",
    "df_results"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "704cecf6-2c87-4356-b9be-26f4346c194f",
   "metadata": {},
   "source": "### Збільшення кількості учнів\nТут ми збільшуємо `num_learners` з 10 → 30, зберігаючи `regularization = 7`.\n\n- Більше учнів розширює простір гіпотез, дозволяючи моделі фіксувати більш тонкі закономірності, що може помірно підвищити F1.\n- У більшості випадків різниця в часі виконання між 10 та 30 учнями не є суттєвою, що вказує на те, що додаткова ширина схеми не значно збільшує вартість виконання.\n- Покращення якості все ще слідує *кривій спадної віддачі*: ранні прирости з'являються, коли ансамбль росте, але вони виходять на плато, оскільки додаткові учні вносять менше нової інформації.\n\nЦей експеримент підкреслює компроміс між якістю та ефективністю — збільшення ширини ансамблю може забезпечити невеликі прирости точності без значного штрафу за час виконання, залежно від бекенду та умов транспіляції."
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "0f15c5fb-2450-4671-9bc2-471043414df2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<Image src=\"../docs/images/tutorials/sml-classification/extracted-outputs/0f15c5fb-2450-4671-9bc2-471043414df2-0.avif\" alt=\"Output of the previous code cell\" />"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "x = np.arange(len(df_results))\n",
    "width = 0.35\n",
    "plt.figure(figsize=(7.6, 4.6))\n",
    "plt.bar(x - width / 2, df_results[\"Accuracy\"], width=width, label=\"Accuracy\")\n",
    "plt.bar(x + width / 2, df_results[\"F1\"], width=width, label=\"F1\")\n",
    "plt.xticks(x, df_results[\"Config\"], rotation=10)\n",
    "plt.ylabel(\"Score\")\n",
    "plt.title(\"Classical vs Quantum ensemble performance\")\n",
    "plt.legend()\n",
    "plt.ylim(0, 1.0)\n",
    "plt.tight_layout()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "745cd406-5166-4eb9-8506-0eedd71e9b79",
   "metadata": {},
   "source": [
    "### Interpretation\n",
    "\n",
    "The plot confirms the expected scaling pattern. The classical AdaBoost performs strongly for smaller ensembles but becomes increasingly costly to scale as the number of weak learners grows, because its subset-selection problem expands combinatorially. The quantum-enhanced models replicate classical accuracy at low widths and begin to surpass it as ensemble size increases, especially under adaptive α-regularization. This reflects the quantum optimizer’s ability to sample and evaluate many candidate subsets in parallel through superposition, maintaining tractable search even at higher widths. While current hardware overhead offsets some of the theoretical gains, the trend illustrates the scaling efficiency advantage of the quantum formulation. In practical terms, the classical method remains preferable for lightweight benchmarks, while quantum-enhanced ensembles become advantageous as model dimensionality and ensemble size expand, offering better trade-offs between accuracy, generalization, and computational growth."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a27afb68-f959-4f4a-910c-0aadafb7e18e",
   "metadata": {},
   "source": [
    "## Appendix: Scaling benefits and enhancements\n",
    "\n",
    "The scalability advantage of the `QuantumEnhancedEnsembleClassifier` arises from how the ensemble-selection process maps to quantum optimization.\n",
    "Classical ensemble learning methods, such as AdaBoost or random forests, become computationally expensive as the number of weak learners increases because selecting the optimal subset is a combinatorial problem that scales exponentially.\n",
    "\n",
    "In contrast, the quantum formulation — implemented here via the Quantum Approximate Optimization Algorithm (QAOA) — can explore these exponentially large search spaces more efficiently by evaluating multiple configurations in superposition.\n",
    "As a result, the training time does not grow significantly with the number of learners, allowing the model to remain efficient even as ensemble width increases.\n",
    "\n",
    "While current hardware introduces some noise and depth limitations, this workflow demonstrates a near-term hybrid approach where classical and quantum components cooperate: the quantum optimizer provides a better initialization landscape for the classical loop, improving convergence and final model quality.\n",
    "As quantum processors evolve, these scalability benefits are expected to extend to larger datasets, broader ensembles, and deeper circuit depths."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ee41a301",
   "metadata": {},
   "source": [
    "## References\n",
    "\n",
    "1. [Introduction to Qiskit Functions](/docs/guides/functions)\n",
    "2. [Multiverse Computing Singularity Machine Learning](/docs/guides/multiverse-computing-singularity)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2cb5785c",
   "metadata": {},
   "source": [
    "## Tutorial survey\n",
    "\n",
    "Please take a minute to provide feedback on this tutorial. Your insights will help us improve our content offerings and user experience.\n",
    "\n",
    "[Link to survey](https://your.feedback.ibm.com/jfe/form/SV_3BLFkNVEuh0QBWm)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3"
  },
  "colab": {
   "cell_execution_strategy": "setup"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}